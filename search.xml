<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[知识汇集]]></title>
    <url>%2Fpublic%2F2019%2F06%2F01%2Findex-work%2F</url>
    <content type="text"><![CDATA[其实，准备面试也是一个不断学习的过程，很多技术要求自己从更加底层的角度去学习，死记硬背是肯定不行的，需要去理解每一个技术，从更高的角度去学习东西。 JVM垃圾回收机制：https://www.toutiao.com/i6691966641242112516/ 蚂蚁金服面试：https://mp.weixin.qq.com/s/-MzmdxqukOZ6rUta9nkGGw JAVA线程池：https://www.toutiao.com/i6687903955726369287/ 类加载过程：https://www.toutiao.com/i6691887815241761293/]]></content>
      <categories>
        <category>知识汇集</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单体架构&微服务架构]]></title>
    <url>%2Fpublic%2F2019%2F05%2F29%2Fsingle-to-micro-service%2F</url>
    <content type="text"><![CDATA[单体架构基本介绍一个项目包（war包）包含了应用的所有功能, 在没有出现微服务概念之前，基本上都是这种架构形式存在， 我们一般把程序打包成一个文件后，扔到tomcat等应用服务器中即可 优缺点优点 项目架构简单,前期开发的成本低,周期短 功能都在本地，没有分布式的管理开销和调用开销 运维简单缺点 开发效率低：所有的开发在一个项目改代码，递交代码相互等待，代码冲突不断 代码维护难：代码功能耦合在一起，新人不知道何从下手 部署不灵活：构建时间长，任何小修改必须重新构建整个项目，这个过程往往很长 稳定性不高：一个微不足道的小问题，可以导致整个应用挂掉 扩展性不够：单体应用只能作为一个整体进行扩展，无法结合业务模块的特点进行伸缩 技术升级难：单体应用往往使用统一的技术平台或方案解决所有问题，团队的每个成员都必须使用相同的开发语言和框架，想要引入新的框架或技术平台会非常困难 微服务架构基本介绍微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相协作（通常是基于HTTP协议的RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立的部署。 优缺点优点 开发简单 技术栈灵活 服务独立无依赖 独立按需扩展 可用性高 缺点（挑战） 系统架构复杂，对开发者要求高 系统部署依赖 服务间通信成本 数据一致性 系统集成测试 多服务运维难度 性能监控 ……]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>单体架构</tag>
        <tag>微服务架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载过程]]></title>
    <url>%2Fpublic%2F2019%2F05%2F28%2Fclass-load-study%2F</url>
    <content type="text"><![CDATA[类加载过程Class 文件需要加载到虚拟机中之后才能运行和使用，那么虚拟机是如何加载这些 Class 文件呢？ 系统加载 Class 类型的文件主要三步:加载-&gt;连接-&gt;初始化。连接过程又可分为三步:验证-&gt;准备-&gt;解析。 加载类加载过程的第一步，主要完成下面3件事情： 通过全类名获取定义此类的二进制字节流将字节流所代表的静态存储结构转换为方法区的运行时数据结构在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口虚拟机规范多上面这3点并不具体，因此是非常灵活的。比如：”通过全类名获取定义此类的二进制字节流” 并没有指明具体从哪里获取、怎样获取。比如：比较常见的就是从 ZIP 包中读取（日后出现的JAR、EAR、WAR格式的基础）、其他文件生成（典型应用就是JSP）等等。 一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 类加载器、双亲委派模型也是非常重要的知识点，这部分内容会在后面的文章中单独介绍到。 加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。 验证 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。这里所设置的初始值”通常情况”下是数据类型默认的零值（如0、0L、null、false等），比如我们定义了public static int value=111 ，那么 value 变量在准备阶段的初始值就是 0 而不是111（初始化阶段才会复制）。特殊情况：比如给 value 变量加上了 fianl 关键字public static final int value=111 ，那么准备阶段 value 的值就被复制为 111。基本数据类型的零值： JVM必问知识点:类加载过程基本数据类型的零值 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方发表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。 综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。 初始化初始化是类加载的最后一步，也是真正执行类中定义的 Java 程序代码(字节码)，初始化阶段是执行类构造器 ()方法的过程。 对于（） 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 （） 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。 对于初始化阶段，虚拟机严格规范了有且只有5中情况下，必须对类进行初始化： 当遇到 new 、 getstatic、putstatic或invokestatic 这4条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。使用 java.lang.reflect 包的方法对类进行反射调用时 ，如果类没初始化，需要触发其初始化。初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。当使用 JDK1.7 的动态动态语言时，如果一个 MethodHandle 实例的最后解析结构为 REF_getStatic、REF_putStatic、REF_invokeStatic、的方法句柄，并且这个句柄没有初始化，则需要先触发器初始化。 原文：https://www.toutiao.com/i6691887815241761293/]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>类加载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql优化]]></title>
    <url>%2Fpublic%2F2019%2F05%2F28%2Fmysql-optimize%2F</url>
    <content type="text"><![CDATA[MySQL优化是一个程序员的基本素养，每个程序员基本上都具备，但是，越是简单常见的东西，越容易忽视。如何写出一个高质量的SQL语句其实是非常重要的。在渠道端重构中遇到过一下几个慢SQL场景（线上基本情况：订单量700w+）1）借款查询：借款查询搜索项特别多，仅搜索项就有20+，需要关联五六张表才能满足业务需求，查询效率不高；【单体系统-服务化后，表已经垂直拆分，记录中心维护一张宽表满足需求】2）数据权限问题：线上营业部大概有700+，当查询者拥有营业部权限特别多时，查询效率进一步下降；【基础服务冗余一张权限表，权限数据由sso服务统一维护】3) 大分页跳转问题：选择大分页时，性能极具恶化；【优化sql，使用覆盖索引可以解决这一问题】4) 业务层次优化：为了减小搜索范围，从业务方面去谈，最终确定所有范围查询都带上订单创建时间（默认半年，可以手动扩大）整体的核心思想：就是让索引生效，否则在大数据量的场景下，查询效率一定比较低。至于什么样的sql不走索引，这个就太多了。实际中可以用explain去分析。其他更多mysql优化技巧见后续文章数据量达到百万级以后，就需要思考如何去优化查询效率了，大致有以下思考方面： 优化索引&amp;优化SQL（常规手段，优化策略太多了，可以结合explain+慢sql语句去定位分析问题） 加缓存（数据一致性问题） 读写分离（如果有必要，可以做读写分离，相当于简单的分库） 分区（mysql的分区没有oracle性能好） 分表（垂直拆分和水平拆分，都需要结合业务场景来分析出最合适的拆分策略，拆的不好，反而会起反作用） 分库（暂时未涉及） 换NoSql数据库【需要看业务场景，是否能满足】 其他参考资料 索引介绍：https://www.toutiao.com/a6697059671313744387/ 索引原理1：https://www.toutiao.com/a6682541875695452685/ 索引原理2：https://www.toutiao.com/a6664353367969497612/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收机制]]></title>
    <url>%2Fpublic%2F2019%2F05%2F28%2Fgarbage-collect-study%2F</url>
    <content type="text"></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>垃圾回收机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2Fpublic%2F2019%2F05%2F28%2Fthread-pool-study%2F</url>
    <content type="text"><![CDATA[参考资料 https://www.toutiao.com/a6614005147502641671/]]></content>
      <categories>
        <category>线程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务补偿]]></title>
    <url>%2Fpublic%2F2019%2F05%2F26%2Fdistributed-transaction-compensation%2F</url>
    <content type="text"><![CDATA[从单体系统演变成服务化项目后，我们面临的三大难题：服务的拆分、服务故障传播、分布式事务。 服务的拆分：重点在于架构师对于业务场景的分析和理解，拆分成恰当的粒度，以便未来扩展； 服务的故障传播：通过ribbon和hytrix基本上可以解决这一问题； 今天重点想聊得是“分布式事务”问题； 前言这个问题是我在做项目过程中真实经历过的，再深入聊解决方案之前，我想先聊下分布式环境下的两大原理。 CAP定理 一致性(Consistency) ：客户端知道一系列的操作都会同时发生(生效) 可用性(Availability)：每个操作都必须以可预期的响应结束 分区容错性(Partition tolerance)：即使出现单个组件无法可用,操作依然可以完成 BASE理论 Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 解决方案两阶段提交核心思想：先准备资源，然后统一提交执行，类似于数据库上的事务，只不过从数据库提升至业务级别上了，但是实现会更加复杂。 小结：没有采用这种方案，主要是实现复杂，而且性能还比较低，牺牲了可用性。 补偿事务核心思想：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作，它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 本地消息表核心思想：将分布式事务拆分成本地事务进行处理，基本思路就是： 消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 最终采用的解决方案我们吸收了以上主流的解决方案，形成了目前的解决方案，主要思路如下 首先对当前应用场景进行分析 第一步，明确当前场景是否需要进行分布式补偿 第二步，确定需要补偿的时候，需要业务拆解成不同的步骤 实际执行的时候，第一个步骤比较重要，需要对入参进行严格的参数校验以及其他业务性校验，以保证后续业务需要 如果校验未通过，如果是同步接口，直接返回响应错误信息，如果是异步接口，调用异步错误信息通知接口告知调用者； 如果校验通过，则保存相关业务数据，并且同时生成一条补偿记录；【特别注意：业务数据的保存和补偿记录放在一个数据库事务里】 后续步骤如果出现失败，则更新补偿记录表相关处理状态； 还需要配置补偿定时任务，每个固定时间扫描补偿信息表，如果发现执行失败记录，则进行重试，如果连续补偿次数达到阈值，则将状态更新为error，停止补偿； 还需要配置一个人工运维的定时任务，如果发现状态为error并且还未进行邮件预警的记录，则发告警邮件，需要人工运维；]]></content>
      <categories>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>技术难点</tag>
        <tag>分布式</tag>
        <tag>补偿机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown画UML图]]></title>
    <url>%2Fpublic%2F2019%2F05%2F10%2Fmarkdown-uml%2F</url>
    <content type="text"><![CDATA[使用markdown写作的时候，画UML图是基本诉求。如果通过专业的工具来画，再导成图片引入，整套流程下来特别耗时，如果感觉不合适，再调整，时间周期会更长。 MarkDown是可以画UML图的，虽然效果没有专业工具好看，但是，掌握基本语法后，会极大提升写作效率。 plantUml配置安装插件1npm install hexo-tag-plantuml --save 顺序语法介绍 关键字start 和stop表示图示的开始和结束 活动标签(activity label)以冒号开始，以分号结束【: ;】 顺序示例代码12345678&#123;% plantuml %&#125;start:配置Java环境; :下载pantuml.jar;:编写描述文件; :执行; stop&#123;% endplantuml %&#125; 顺序示例效果图 if-else语法介绍 关键字if,then和else设置分支测试，关键字elseif可以设置多个分支 if-else示例代码123456789&#123;% plantuml %&#125;startif (判断条件) then (yes):执行yes操作;else (no):执行no操作;endifstop&#123;% endplantuml %&#125; if-else示例效果图 repeat语法介绍 可以使用关键字repeat和repeatwhile进行重复循环 repeat示例代码12345678&#123;% plantuml %&#125;startrepeat:int i=1;:执行i++;repeat while (i&lt;=100)stop&#123;% endplantuml %&#125; repeat示例效果图 while语法介绍 可以使用关键字while和end while进行while循环; while示例代码12345678&#123;% plantuml %&#125;start:i=1;while(i&lt;100):i++;endwhilestop&#123;% endplantuml %&#125; while示例效果图 fork语法介绍 关键字fork，fork again和end fork表示并行处理 fork示例代码1234567891011121314&#123;% plantuml %&#125;startif(条件判断) then (yes)fork:并行操作1;fork again:并行操作2;end forkelse(no):执行1;:执行2;endifstop&#123;% endplantuml %&#125; fork示例效果图 文本格式注释 title 标题，#color 颜色 使用-&gt;标记，你可以给箭头添加文字或者修改箭头颜色 -&gt;示例代码12345678910111213&#123;% plantuml %&#125;startif(条件判断) then (yes)-[#blue]-&gt;:执行操作1;-[#green]-&gt;:执行操作2;else(no)-[#black]-&gt;:执行1;endifstop&#123;% endplantuml %&#125; -&gt;示例效果图 时序图语法介绍 用-&gt;来绘制参与者之间传递的消息，用 “–&gt;” 绘制一个虚线箭头表示异步消息 用:消息描述 用关键字actor表示参与者 用database标识数据库 用关键字participant声明参与者 用#RGB值或者颜色名修改 actor 或参与者的背景颜色 用self-&gt;self给自己发消息 用[#RGB]修改箭头颜色-[#red]&gt;或-[#red]-&gt; 用关键字autonumber用于自动对消息编号 用skinparam命令改变颜色和字体 时序图示例代码123456789101112131415161718&#123;% plantuml %&#125;actor Userparticipant &quot;流程服务&quot; as Aparticipant &quot;组合服务&quot; as Bparticipant &quot;基础服务&quot; as CUser -&gt; A:查询列表activate AA -&gt; B: 查询列表activate BB -&gt; C: 查询列表activate CC --&gt; B: 返回deactivate CB--&gt;A:返回deactivate BA --&gt; User:返回deactivate A&#123;% endplantuml %&#125; 时序图示例图 组件图描述 组件用[]括号起来 组件图代码12345678910111213141516171819202122232425262728&#123;% plantuml %&#125;package &quot;包组合&quot; &#123; HTTP - [包一组件] [包二组件]&#125;node &quot;节点组合&quot; &#123; FTP - [节点一组件] [包一组件] --&gt; FTP&#125;cloud &quot;云服务&quot; &#123; [云里一]&#125;database &quot;数据库服务&quot; &#123; folder &quot;文件夹组合&quot; &#123; [文件夹一] &#125; frame &quot;帧组合&quot; &#123; [帧二] &#125;&#125;[包二组件] --&gt; [云里一][云里一] --&gt; [文件夹一][文件夹一] --&gt; [帧二]&#123;% endplantuml %&#125; 组件图示例]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例设计模式]]></title>
    <url>%2Fpublic%2F2019%2F05%2F06%2Fsingleton-design-pattern%2F</url>
    <content type="text"><![CDATA[简介单例模式 (Singleton) 是一种创建型模式，指某个类采用Singleton模式，则在这个类被创建后，只可能产生一个实例供外部访问，并且提供一个全局的访问点。 UML图 具体实现简单点说，就是一个应用程序中，某个类的实例对象只有一个，你没有办法去new，因为构造器是被private修饰的，一般通过getInstance()的方法来获取它们的实例。getInstance()的返回值是一个同一个对象的引用，并不是一个新的实例 1) 饿汉式特点：线程安全，无法实现实例懒加载策略。123456789101112public class Singleton1 &#123; private final static Singleton1 singleton1 = new Singleton1(); private Singleton1() &#123; &#125; public static Singleton1 getInstance() &#123; return singleton1; &#125;&#125; 2) 懒汉式特点：线程不安全，实现了实例懒加载策略。12345678910111213141516public class Singleton2 &#123; private static Singleton2 singleton2; private Singleton2() &#123; &#125; public static Singleton2 getInstance() &#123; if (singleton2 == null) singleton2 = new Singleton2(); return singleton2; &#125;&#125; 3) 全局锁式特点：线程安全，且实现了懒加载策略，但是线程同步时效率不高。12345678910111213141516public class Singleton3 &#123; private static Singleton3 singleton3; private Singleton3() &#123; &#125; public synchronized static Singleton3 getInstance() &#123; if (singleton3 == null) singleton3 = new Singleton3(); return singleton3; &#125;&#125; 4) 双重校验锁式 特点：线程安全，且实现了懒加载策略，同时保证了线程同步时的效率；实现复杂，且 volatile 需要在JDK1.5之后的版本才能确保安全。12345678910111213141516171819public class Singleton4 &#123; private static volatile Singleton4 singleton4; private Singleton4() &#123; &#125; public static Singleton4 getInstance() &#123; if (singleton4 == null) &#123; synchronized (Singleton4.class) &#123; if (singleton4 == null) &#123; singleton4 = new Singleton4(); &#125; &#125; &#125; return singleton4; &#125;&#125; 为什么加volatile修饰？ 多线程场景下，如果不增加volatile，还是可能存在工作线程里的副本已经初始化了实例，但是主线程的实例还是空，此时如果有其他线程恰好同时请求该实例，还是会再次初始化。 5) 静态代码块式 特点：线程安全，类主动加载时才初始化实例，实现了懒加载策略，且线程安全。12345678910111213141516public class Singleton5 &#123; private static Singleton5 singleton5; private Singleton5() &#123; &#125; static &#123; singleton5 = new Singleton5(); &#125; public static Singleton5 getInstance() &#123; return singleton5; &#125;&#125; 6) 静态内部类式特点：线程安全，不存在线程同步问题，且单例对象在程序第一次 getInstance() 时主动加载 SingletonHolder 和其 静态成员 INSTANCE，因而实现了懒加载策略；多创建了一个类；1234567891011121314public class Singleton6 &#123; private Singleton6() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton6 INSTANCE = new Singleton6(); &#125; public static Singleton6 getInstance() &#123; return Singleton6.SingletonHolder.INSTANCE; &#125;&#125; 7) 枚举方式特点：线程安全，不存在线程同步问题，且单例对象在枚举类型 INSTANCE 第一次引用时通过枚举的 构造函数 初始化，因而实现了懒加载策略；可以防止反序列化；123456789101112131415161718192021public class Singleton7 &#123; private Singleton7() &#123; &#125; enum SingletonEnum &#123; INSTANCE; private final Singleton7 singleton7; private SingletonEnum() &#123; singleton7 = new Singleton7(); &#125; &#125; public static Singleton7 getInstance() &#123; return SingletonEnum.INSTANCE.singleton7; &#125;&#125; 推荐使用哪一种？这个问题我觉得没有标准答案，需要根据实际的业务场景进行分析。 如果这个单例类初始化开销很低，那么第一种最好，代码简单清晰，线程安全； 如果这个单例类初始化开销很大，要求一定要在实际使用时才初始化 如果当前应用环境不是多线程环境，那么第二种最好，代码简单，而且效率高； 如果是多线程环境，并且单例类中只有这一个方法需要枷锁处理，那么第三种最好； 如果这个单例类中，很多方法都要加锁处理，那么方法级的加锁，会影响效率，所以第四、五、六种选择也不错； 如果单例模式的使用场景更加复杂，如还可能通过反射或者反序列化获取单例实例，那么采用第七种，或者四、五、六在加一部分防止反射和反序列化的代码 123456private Singleton() &#123; // 防止反射获取多个对象的漏洞 if (null != instance) &#123; throw new RuntimeException(); &#125; &#125; 123456// 防止反序列化获取多个对象的漏洞。// 无论是实现Serializable接口，或是Externalizable接口，当从I/O流中读取对象时，readResolve()方法都会被调用到。// 实际上就是用readResolve()中返回的对象直接替换在反序列化过程中创建的对象。private Object readResolve() throws ObjectStreamException &#123; return instance;&#125; 优缺点分析优点 单例模式在内存中只有一个实例，减少了内存开支，尤其是频繁的创建和销毁实例。 由于只生成一个实例，所以减少了系统的性能开销。 避免对资源的多重占用，例如写文件操作。 单例模式可以在系统设置全局的访问点，优化和共享资源访问 缺点 单例模式对测试不利。 单例模式与单一职责原则有冲突，一个类应该只实现一个逻辑，而不用关心它是否是单例的。应用场景 Spring里的@Service，@Component等注释的bean，默认都是单例 编程的时候一定要注意到这一点，一些新手容易忽视这一点，容易在单例类中加一些私有变量，在单例模式下，这些私有变量都是共享资源，多线程环境下使用时容易出问题 尽量把业务实现尽量做成“无状态”的，这样容易做负载均衡，支持更高的并发]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>创建型</tag>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[欧拉函数]]></title>
    <url>%2Fpublic%2F2019%2F05%2F04%2Foula%2F</url>
    <content type="text"><![CDATA[对正整数n，欧拉函数是小于n且和n互质的正整数(包括1)的个数。 例如Euler(8)=4，因为1,3,5,7均和8互质,下面用E(n)表示欧拉函数的值。​&gt; 在数论中，对于正整数N,少于或等于N ([1,N]),且与N互质的正整数(包括1)的个数，记作φ(n)。 ​ φ函数的值： $$φ(x)=x(1- \frac 1{p(1)})(1- \frac1{p(2)})(1-\frac1{p(3)})(1-\frac1{p(4)})…..(1-\frac1{p(n)})$$​ 其中p(1),p(2)…p(n)为x的所有质因数; ​ φ(1)=1(唯一和1互质的数，且小于等于1)。注意：每种质因数只有一个。 ​ 例如: ​ φ(10)=10×(1-1/2)×(1-1/5)=4; 分别为：1 3 7 9 ​ φ(30)=30×(1-1/2)×(1-1/3)×(1-1/5)=8; ​ φ(49)=49×(1-1/7)=42; 欧拉函数的性质： 对于素数p，φ(p) = p-1，对于两个素数p,q，φ(pq) = pq-1。 欧拉函数是积性函数，但不是完全积性函数。即φ(mn)=φ(m)*φ(n)，只有(n,m)=1时成立。 对于一个正整数N的素数幂分解$N = {P_1}^{q^1}{P_2}^{q^2}…*{P_n}^{q^n}$。 $φ(x)=x(1- \frac 1{p(1)})(1- \frac1{p(2)})(1-\frac1{p(3)})(1-\frac1{p(4)})…..(1-\frac1{p(n)})$ 除了N=2，φ(N)都是偶数。 设N为正整数，$\sumφ(d) = N(d|N)$。 根据性质2，我们可以在(sqrt(n))的时间内求一个数的欧拉函数值。 延伸：一个数的所有质因子之和是euler(n)*n/2。 欧拉函数模板 123456789101112131415161718192021222324252627282930313233343536//直接求小于或等于n,且与n互质的个数: int Euler(int x)&#123; int ret=x; int n=(int)sqrt(x*1.0); //如果判断条件改为i*i&lt;=n,这里的i*i就会做sqrt(n)次,每次循环都要算一次，养成好习惯 for(int i=2;i&lt;=n;i++) if(n%i==0)&#123; ret=ret/i*(i-1);//先进行除法防止溢出(ret=ret*(1-1/p(i))) while(n%i==0) n/=i; &#125; if(n&gt;1) ret=ret/n*(n-1); return ret;&#125; //筛选模板:求[1,n]之间每个数的质因数的个数#define size 1000001int euler[size];void Init()&#123; memset(euler,0,sizeof(euler)); euler[1]=1; for(int i=2;i&lt;size;i++) if(!euler[i]) for(int j=i;j&lt;size;j+=i)&#123; if(!euler[j]) euler[j]=j; euler[j]=euler[j]/i*(i-1);//先进行除法是为了防止中间数据的溢出 &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>欧拉函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Study]]></title>
    <url>%2Fpublic%2F2019%2F05%2F03%2Fredis-study%2F</url>
    <content type="text"><![CDATA[Redis是当前比较热门的NOSQL系统之一，它是一个开源的使用ANSI c语言编写的key-value存储系统（区别于MySQL的二维表格的形式存储。）。和Memcache类似，但很大程度补偿了Memcache的不足。和Memcache一样，Redis数据都是缓存在计算机内存中，不同的是，Memcache只能将数据缓存到内存中，无法自动定期写入硬盘，这就表示，一断电或重启，内存清空，数据丢失。所以Memcache的应用场景适用于缓存无需持久化的数据。而Redis不同的是它会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，实现数据的持久化. Redis的机制高性能Redis最牛逼的地方就是快，为什么这么快呢，主要原因如下 纯内存操作 数据结构简单，对数据操作也简单 单线程操作，避免了频繁的上下文切换 单线程好处：1.代码更清晰，处理逻辑更简单；2.不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；3.不存在多进程或者多线程导致的切换而消耗CPU 单线程劣势：无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善； 采用了非阻塞I/O多路复用机制 IO多路复用是需要操作系统支持的，目前，提供的多路复用函数库主要有四下个方法select、poll、epoll、kqueue等 名词比较绕口，理解涵义就好。从网上抄来的一个epoll场景： 一个酒吧服务员（一个线程），前面趴了一群醉汉，突然一个吼一声“倒酒”（事件），你小跑过去给他倒一杯，然后随他去吧，突然又一个要倒酒，你又过去倒上，就这样一个服务员服务好多人，有时没人喝酒，服务员处于空闲状态，可以干点别的玩玩手机。至于epoll与select，poll的区别在于后两者的场景中醉汉不说话，你要挨个问要不要酒，没时间玩手机了。epoll是linux下内核支持的函数，而kqueue是其他系统支持的函数。io多路复用大概就是指这几个醉汉共用一个服务员。 高可用性了解一个技术的时候，一定要自己不断的去思考，为什么会出现这个技术，这个技术解决了什么问题，以及怎样解决的。Redis还有一个很牛逼的特性就是高可用性，Redis是如何做到的呢，主要原因如下 支持持久化机制，用于解决机器故障导致内存数据丢失的问题 支持主从复制，用于解决读取数据压力大问题 支持哨兵机制，能够及时做到故障转移 支持集群机制，能够扩充Redis可以存放的数据量 支持过期策略以及内存淘汰机制，解决写入数据高于Redis总内存问题 事务控制和分布式锁，保证并发场景下正常的使用Redis 下面依次分析这几个机制 持久化机制持久化作用Redis持久化就是按照一定的机制及时将内存里的数据同步至磁盘。为什么要去支持持久化呢？Redis之前比较流行的内存数据库是memcached，由于它的数据都存储到内存里了，就导致它有一个很致命的缺陷，就是一旦机制出现故障，所有数据就会丢失，这一点就一定决定了memcached的应用场景会非常受限，只能应用于一些非核心业务，可以接受数据丢失。持久化机制 RDB可以在指定的时间间隔内生成数据集的时间点快照 AOF持久化记录服务器执行的所有写操作命令 同时启用AOF和RDB当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。为了缓解这一问题，Redis支持Rewrite重写，简单的讲就是基于一定算法，给Aof文件“瘦身”。 优缺点分析 RDB Redis会单独启动一个进程，先把数据收集到一个临时文件，等待上一个持久化操作结束后，并且按照你配置的持久策略去把数据同步到磁盘，对主进程无影响，性能高，但是缺点是，一旦出现机器故障，放在缓存里的数据就会丢失。RDB策略配置示例如下（redis.conf）每900s有一次写操作触发同步，或者每300s有10次写操作触发同步，或者每60s有10000次操作触发同步 123save 900 1save 300 10save 60 10000 AOF Redis会将自己所有执行过的更新指令记录下来，并且日志文件只允许尾部添加操作。恢复数据的时候，Redis会从头到尾重新执行一遍。Aof目前同步策略：Always（每步）Everysec（每一秒）No（操作系统决定）。开启aof配置，以及同步策略配置示例如下（redis.conf）开启aof，每秒同步一次写操作到磁盘 12appendonly yes appendfsync everysec 这两种机制没有好坏之说，使用的时候，需要你去分析自己的实际业务场景，哪个适合用哪个！参考链接：Redis持久化 主从复制作用Redis相对于传统的db，读写非常快的，但是，面对更大的读请求来临时，Redis提供了主从复制策略来解决读取数据压力大问题结构Redis 主从master-slave级联图 主从同步策略 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。开启从服务器配置（redis.conf）将当前服务器配置成192.168.1.1 6379 这个节点的从服务器1slaveof 192.168.1.1 6379 参考链接：主从复制 哨兵作用如果Redis主节点跪了的话，如何来保证Redis系统可用性呢？Redis提供了哨兵机制，哨兵会去监控Redis节点，当发现Redis主节点跪了的时候，会通过投票机制，从从节点中挑取一个节点自动升级为主节点，自动实现故障转移，同事还会向管理员发送Redis节点异常通知。结构Redis 哨兵监控图(哨兵也可以多个)哨兵原理介绍 首先理解两个名词 主观下线：当前哨兵节点连接某一Redis节点失败； 客观下线：当sentinel监视的某个服务主观下线后，sentinel会询问其它监视该服务的sentinel，看它们是否也认为该服务主观下线，接收到足够数量（这个值可以配置）的sentinel判断为主观下线，既任务该服务客观下线，并对其做故障转移操作。选举领头哨兵 一个redis服务被判断为客观下线时，多个监视该服务的sentinel协商，选举一个领头sentinel，对该redis服务进行古战转移操作。选举领头sentinel会遵循一些规则，有兴趣可以自行调研。 注：你可能会关心为啥选举领头哨兵，其实道理很简单，做故障迁移的时候，不可能每个哨兵节点都私自决定用哪个节点替代坏掉的主节点， 会乱套的，公平的投出一个节点作为领头者，然后基于一定规则去做故障转移最快进行故障转移，分为三个主要步骤：1) 从下线的主服务的所有从服务里面挑选一个从服务，将其转成主服务；2) 已下线主服务的所有从服务改为复制新的主服务；3) 将已下线的主服务设置成新的主服务的从服务，当其回复正常时，复制新的主服务，变成新的主服务的从服务。参考链接：Redis哨兵 集群作用一台Redis节点内存资源总是有限的，如果不够使的话，怎么能扩展吗？Redis是支持集群的，默认关闭。开启集群配置(redis.conf) 1cluster-enabled yes #开启cluster Redis集群架构图上能看到的信息：1) 对象保存到Redis之前先经过CRC16哈希到一个指定的Node上，例如Object4最终Hash到了Node1上。2) 每个Node被平均分配了一个Slot段，对应着0-16384，Slot不能重复也不能缺失，否则会导致对象重复存储或无法存储。3) Node之间也互相监听，一旦有Node退出或者加入，会按照Slot为单位做数据的迁移。例如Node1如果掉线了，0-5640这些Slot将会平均分摊到Node2和Node3上,由于Node2和Node3本身维护的Slot还会在自己身上不会被重新分配，所以迁移过程中不会影响到5641-16384Slot段的使用。 简单总结下哈希Slot的优缺点： 优点：将Redis的写操作分摊到了多个节点上，提高写的并发能力，扩容简单。 缺点：每个Node承担着互相监听、高并发数据写入、高并发数据读出，工作任务繁重 延展性问题：redis为什么采用一致性hash，而没有采用传统的取模算法？其实道理很简答，因为在集群环境下，新增节点或者节点失效是很常见的，如果采用取模的那种算法，每次新增或者删除节点时，所有与数据都可能需要重新调整位置，这是无法接受的！结合redis集群和主从复制两种思想，可以得到Redis集群的最终形态 想扩展并发读就添加Slaver，想扩展并发写就添加Master，想扩容也就是添加Master，任何一个Slaver或者几个Master挂了都不会是灾难性的故障。完美！参考链接：Redis集群设计原理 内存数据管理方案作用这一部分对应的问题很常见，就是如果你的redis只能存5g数据，可是你写入了10g数据，那么内存里最终会保留哪5g数据的问题。redis采用的是定期删除+惰性删除策略。 为什么不用定时删除策略?定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略. 定期删除+惰性删除是如何工作的呢?定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置示例(当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key)1maxmemory-policy volatile-lru 参考链接：分布式之redis复习精讲 Redis事务和分布式锁Redis事务核心操作：multi开启事务，exec执行事务，discard撤销事务，watch监控key是否改过、UNWATCH对应watch操作【multi和exec执行后会自动unwatch调监控队列里的所有key，如果想提前释放，可以用这个命令】 redis事务采用的是乐观锁，就是先处理，再真正去执行的时候去看有没有被修改过，没有的话，就去更新，否则报错。这个思想是不是有点似曾相识，是的，concurrenthashmap的set值时也是用的这个思想。还是那句话，虽然技术上感觉不搭边，但是思想上确实想通的。 Redis分布式锁核心操作：setNX，理解这个操作基本上就理解了分布式锁。这个方法的意思就是去给一个key“赋值”，如果之前没人这样做过，返回值是1，否则返回0. 参考链接：Redis事务和分布式锁 Redis的缺点Redis会是完美的程序吗？肯定不可能的，世界上就没有完美的东西。我们需要做的事情，分析清楚事物的主要矛盾，在实际开发中，不要犯这些错误就好了。 以下典型问题，重点参考了分布式之redis复习精讲 缓存和数据库双写一致性问题问题说明一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。因此，有强一致性要求的数据，不能放缓存。解决方案详细解决方案见分布式之数据库和缓存双写一致性方案解析 缓存雪崩问题缓存击穿问题和缓存雪崩问题都是大项目中可能会遇到，小项目比较难遇到。问题说明黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常解决方案1) 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试2) 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。3) 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 缓存击穿问题问题说明缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常解决方案1) 给缓存的失效时间，加上一个随机值，避免集体失效。2) 使用互斥锁，但是该方案吞吐量明显下降了。3) 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点 I 从缓存A读数据库，有则直接返回 II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。 III 更新线程同时更新缓存A和缓存B。 缓存的并发竞争问题问题说明这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，提前百度了一下，发现答案基本都是推荐用redis事务机制。博主不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。解决方案1) 如果对这个key操作，不要求顺序这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。2) 如果对这个key操作，要求顺序假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳 参考链接：https://www.toutiao.com/i6688926152364392963/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>SourceCode</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eureka Study]]></title>
    <url>%2Fpublic%2F2019%2F05%2F02%2Feureka-study%2F</url>
    <content type="text"><![CDATA[Eureka是基于REST（Representational State Transfer）服务，主要以AWS云服务为支撑，提供服务发现并实现负载均衡和故障转移。我们称此服务为Eureka服务。Eureka提供了Java客户端组件，Eureka Client，方便与服务端的交互。客户端内置了基于round-robin实现的简单负载均衡。在Netflix，为Eureka提供更为复杂的负载均衡方案进行封装，以实现高可用，它包括基于流量、资源利用率以及请求返回状态的加权负载均衡。 Eureka介绍Eureka包含了服务器端和客户端组件。 服务器端，也被称作是服务注册中心，用于提供服务的注册与发现。Eureka支持高可用的配置，当集群中有分片出现故障时，Eureka就会转入自动保护模式，它允许分片故障期间继续提供服务的发现和注册，当故障分片恢复正常时，集群中其他分片会把他们的状态再次同步回来。 客户端组件包含服务消费者与服务生产者。在应用程序运行时，Eureka客户端并把他们缓存到本地并周期性的刷新服务状态。 Eureka原理 第一步，spider会启动一个新的docker容器，并在新容器上部署被启动服务的镜像，然后启动服务； 如果采用的是SpringCloud框架，新起的服务会马上把信息注册到EUREKA上； 如果是非SpringCloud，周期性（默认30s，可通过eureka.client.instance-info-replication-interval-seconds调整）的将信息注册到EUREKA上； 第二步，EUREKA收到客户端上报的注册信息后，将新注册服务信息放到readWriteCacheMap中，同时周期性（默认30s，可通过eureka.server.response-cache-update-interval-ms调整）的将信息刷新到缓存中（readOnlyCacheMap）中 客户端拉取信息是从缓存（readOnlyCacheMap）中拉取的【readOnlyCacheMap这个可通过eureka.server.use-read-only-response-cache=false关闭的，由于目前EUREKA是公用的，基础研发部反馈，默认配置是不能动的】； 如果你通过web页面去查看eureka上客户端的注册信息，看到的数据是readWriteCacheMap中的，也就是说，你即便在页面上看到了新启动服务的信息，也不代表调用方已经获取到了最新的实例信息； 第三步，客户端会定期（默认30s,可通过eureka.client.registry-fetch-interval-seconds调整）从EUREKA上拉取最新的注册信息 第四步，如果客户端采用了ribbon进行负载均衡，ribbon使用ribbon缓存进行负载均衡，客户端会定期（默认30s,可通过ribbon.ServerListRefreshInterval进行调整）最新拉取到的信息同步到ribbon缓存 理解了以上四步，我们思考一个问题，新服务上线，客户端最大可能多久可以拿到最新的服务信息 SpringCloud下=0(首次注册 init registe) + 30(readOnlyCacheMap)+30(client fetch interval)+30(ribbon)=90 非SpringCloud下=30(首次注册 init registe) + 30(readOnlyCacheMap)+30(client fetch interval)+30(ribbon)=120 结论：90s的延迟，完全可能存在这样的场景：新服务已经起来了，老服务已经关闭，但是客户端由于没有拿到最新的地址信息，导致服务出现中断问题。 上面只分析了服务上线的情况，还有服务下线的情况，如果没有做特殊配置的话，EUREKA连续3个心跳周期没有检测到客户端心跳的话，会将这一节点剔除，客户端获取到服务不可用的信息会更晚。 网上查到的资料提醒：现在eureka自动下线存在BUG,自动剔除时间会翻倍，需要6个周期，最长要270s]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>Eureka</tag>
        <tag>SpringCloud</tag>
        <tag>注册中心</tag>
        <tag>技术难点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fpublic%2F2019%2F05%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
